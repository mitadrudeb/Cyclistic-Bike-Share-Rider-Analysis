{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687dbc4a",
   "metadata": {},
   "source": [
    "# Cyclistic Bike-Share Analysis\n",
    "\n",
    "## Phase 1: ASK\n",
    "\n",
    "## Business Problem Statement\n",
    "\n",
    "**Company:** Cyclistic - A bike-share company in Chicago with 5,800+ bikes and 600 docking stations\n",
    "\n",
    "**Challenge:** Annual members are more profitable than casual riders. I need to help convert casual riders into annual members.\n",
    "\n",
    "**My Task:** I will analyze how annual members and casual riders use Cyclistic bikes differently to identify patterns that can inform marketing strategies.\n",
    "\n",
    "## Key Definitions\n",
    "\n",
    "- **Casual Riders:** Customers who purchase single-ride or full-day passes\n",
    "- **Annual Members:** Customers who purchase annual memberships\n",
    "\n",
    "## Success Metrics\n",
    "\n",
    "My analysis should provide:\n",
    "1. Clear differences in usage patterns between member types\n",
    "2. Data-driven insights for marketing strategy\n",
    "3. Actionable recommendations backed by data visualizations\n",
    "\n",
    "## Deliverables\n",
    "\n",
    "I will deliver:\n",
    "1. Clear statement of business task\n",
    "2. Description of data sources\n",
    "3. Documentation of data cleaning process\n",
    "4. Summary of analysis\n",
    "5. Supporting visualizations\n",
    "6. Top 3 recommendations\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e367a33",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Phase 2: PREPARE - Data Collection\n",
    "\n",
    "For this analysis, I am using publicly available data from Divvy Bikes (Cyclistic).\n",
    "\n",
    "**Data Source:** Divvy Bikes (Cyclistic) Historical Trip Data  \n",
    "**License:** Public data from Motivate International Inc.  \n",
    "**Time Period:** January 2024 - December 2024 (12 months)  \n",
    "**Privacy Note:** No personally identifiable information (PII) included\n",
    "\n",
    "### Dataset Information:\n",
    "- **12 CSV files** (one per month)\n",
    "- **Source URL:** https://divvy-tripdata.s3.amazonaws.com/index.html\n",
    "- **File naming convention:** YYYYMM-divvy-tripdata.csv\n",
    "\n",
    "### Files I Downloaded:\n",
    "1. 202401-divvy-tripdata.csv (January 2024)\n",
    "2. 202402-divvy-tripdata.csv (February 2024)\n",
    "3. 202403-divvy-tripdata.csv (March 2024)\n",
    "4. 202404-divvy-tripdata.csv (April 2024)\n",
    "5. 202405-divvy-tripdata.csv (May 2024)\n",
    "6. 202406-divvy-tripdata.csv (June 2024)\n",
    "7. 202407-divvy-tripdata.csv (July 2024)\n",
    "8. 202408-divvy-tripdata.csv (August 2024)\n",
    "9. 202409-divvy-tripdata.csv (September 2024)\n",
    "10. 202410-divvy-tripdata.csv (October 2024)\n",
    "11. 202411-divvy-tripdata.csv (November 2024)\n",
    "12. 202412-divvy-tripdata.csv (December 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db5870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.3.3\n",
      "NumPy version: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Turn off warning messages to keep output clean\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure pandas to display all columns and more rows for better data inspection\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Confirm libraries loaded successfully\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a224ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Exploration : Understanding My Dataset\n",
    "\n",
    "Before combining all the data, I need to explore the structure and contents of the data files to understand what I'm working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e5354e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of CSV files: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the path where my raw data files are stored\n",
    "data_path = '../data/raw'\n",
    "\n",
    "# Get a list of all CSV files in that folder\n",
    "csv_files = []\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.csv'):\n",
    "        csv_files.append(file)\n",
    "\n",
    "# Sort the files in alphabetical order\n",
    "csv_files.sort()\n",
    "\n",
    "# Display how many CSV files I found\n",
    "print(f\"Total number of CSV files: {len(csv_files)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99afdd22",
   "metadata": {},
   "source": [
    "### Loading Sample Data (January 2024)\n",
    "\n",
    "I'll examine one month of data first to understand the structure before processing all files. This helps me understand what columns exist, what data types they have, and if there are any issues I need to address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65dc3718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data loaded successfully!\n",
      "\n",
      "Dataset Shape: 144,873 rows Ã— 13 columns\n",
      "============================================================\n",
      "First 3 rows of the dataset:\n",
      "\n",
      "            ride_id  rideable_type           started_at             ended_at  \\\n",
      "0  C1D650626C8C899A  electric_bike  2024-01-12 15:30:27  2024-01-12 15:37:59   \n",
      "1  EECD38BDB25BFCB0  electric_bike  2024-01-08 15:45:46  2024-01-08 15:52:59   \n",
      "2  F4A9CE78061F17F7  electric_bike  2024-01-27 12:27:19  2024-01-27 12:35:19   \n",
      "\n",
      "  start_station_name start_station_id          end_station_name  \\\n",
      "0  Wells St & Elm St     KA1504000135  Kingsbury St & Kinzie St   \n",
      "1  Wells St & Elm St     KA1504000135  Kingsbury St & Kinzie St   \n",
      "2  Wells St & Elm St     KA1504000135  Kingsbury St & Kinzie St   \n",
      "\n",
      "  end_station_id  start_lat  start_lng    end_lat    end_lng member_casual  \n",
      "0   KA1503000043  41.903267 -87.634737  41.889177 -87.638506        member  \n",
      "1   KA1503000043  41.902937 -87.634440  41.889177 -87.638506        member  \n",
      "2   KA1503000043  41.902951 -87.634470  41.889177 -87.638506        member  \n",
      "============================================================\n",
      "\n",
      " Column Information:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144873 entries, 0 to 144872\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   ride_id             144873 non-null  object \n",
      " 1   rideable_type       144873 non-null  object \n",
      " 2   started_at          144873 non-null  object \n",
      " 3   ended_at            144873 non-null  object \n",
      " 4   start_station_name  125708 non-null  object \n",
      " 5   start_station_id    125708 non-null  object \n",
      " 6   end_station_name    124124 non-null  object \n",
      " 7   end_station_id      124124 non-null  object \n",
      " 8   start_lat           144873 non-null  float64\n",
      " 9   start_lng           144873 non-null  float64\n",
      " 10  end_lat             144585 non-null  float64\n",
      " 11  end_lng             144585 non-null  float64\n",
      " 12  member_casual       144873 non-null  object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 14.4+ MB\n",
      "None\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Basic Statistics:\n",
      "\n",
      "           start_lat      start_lng        end_lat        end_lng\n",
      "count  144873.000000  144873.000000  144585.000000  144585.000000\n",
      "mean       41.897591     -87.646706      41.897755     -87.646784\n",
      "std         0.048839       0.027527       0.048893       0.027542\n",
      "min        41.640000     -87.860000      41.390000     -88.970000\n",
      "25%        41.880000     -87.660000      41.880000     -87.660000\n",
      "50%        41.900000     -87.640000      41.900000     -87.640000\n",
      "75%        41.930000     -87.630000      41.930000     -87.630000\n",
      "max        42.070000     -87.520000      42.370000     -87.440000\n"
     ]
    }
   ],
   "source": [
    "# Load the first CSV file (January 2024) as a sample\n",
    "sample_file_path = '../data/raw/202401-divvy-tripdata.csv'\n",
    "sample_df = pd.read_csv(sample_file_path)\n",
    "\n",
    "# Confirm the file loaded successfully\n",
    "print(\"Sample data loaded successfully!\\n\")\n",
    "\n",
    "# Check how many rows and columns are in this file\n",
    "number_of_rows = sample_df.shape[0]\n",
    "number_of_columns = sample_df.shape[1]\n",
    "print(f\"Dataset Shape: {number_of_rows:,} rows Ã— {number_of_columns} columns\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Look at the first 3 rows to see what the data looks like\n",
    "print(\"First 3 rows of the dataset:\\n\")\n",
    "print(sample_df.head(3))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get detailed information about the columns\n",
    "print(\"\\n Column Information:\\n\")\n",
    "print(sample_df.info())\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show basic statistics for numerical columns\n",
    "print(\"\\nðŸ“Š Basic Statistics:\\n\")\n",
    "print(sample_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93b1c1",
   "metadata": {},
   "source": [
    "### Combining All Monthly Files\n",
    "\n",
    "Now that I understand the structure of one file, I'll combine all 12 monthly files into one complete dataset for the entire year of 2024. This will give me a comprehensive view of the bike-share usage patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33b4ee6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processing file 1/12: 202401-divvy-tripdata.csv - 144,873 rows\n",
      "âœ… Processing file 2/12: 202402-divvy-tripdata.csv - 186,125 rows\n",
      "âœ… Processing file 3/12: 202403-divvy-tripdata.csv - 284,042 rows\n",
      "âœ… Processing file 4/12: 202404-divvy-tripdata.csv - 426,590 rows\n",
      "âœ… Processing file 5/12: 202405-divvy-tripdata.csv - 604,827 rows\n",
      "âœ… Processing file 6/12: 202406-divvy-tripdata.csv - 719,618 rows\n",
      "âœ… Processing file 7/12: 202407-divvy-tripdata.csv - 754,698 rows\n",
      "âœ… Processing file 8/12: 202408-divvy-tripdata.csv - 755,266 rows\n",
      "âœ… Processing file 9/12: 202409-divvy-tripdata.csv - 694,587 rows\n",
      "âœ… Processing file 10/12: 202410-divvy-tripdata.csv - 562,932 rows\n",
      "âœ… Processing file 11/12: 202411-divvy-tripdata.csv - 368,026 rows\n",
      "âœ… Processing file 12/12: 202412-divvy-tripdata.csv - 358,984 rows\n",
      "============================================================\n",
      "âœ… All files combined successfully!\n",
      "Total combined rows: 5,860,568\n",
      "Total columns: 13\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store each month's data\n",
    "all_dataframes = []\n",
    "\n",
    "# Loop through each CSV file\n",
    "for i in range(len(csv_files)):\n",
    "    file_name = csv_files[i]\n",
    "    \n",
    "    # Build the full path to the file\n",
    "    file_path = data_path + '/' + file_name\n",
    "    \n",
    "    # Read the CSV file into a dataframe\n",
    "    monthly_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Add this month's data to our list\n",
    "    all_dataframes.append(monthly_df)\n",
    "    \n",
    "    # Show progress\n",
    "    file_number = i + 1\n",
    "    total_files = len(csv_files)\n",
    "    row_count = len(monthly_df)\n",
    "    print(f\"âœ… Processing file {file_number}/{total_files}: {file_name} - {row_count:,} rows\")\n",
    "\n",
    "# Combine all monthly dataframes into one large dataframe\n",
    "df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# Show summary of combined data\n",
    "print(\"=\" * 60)\n",
    "print(\"âœ… All files combined successfully!\")\n",
    "print(f\"Total combined rows: {len(df):,}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c78b59b",
   "metadata": {},
   "source": [
    "### Examining the Combined Dataset\n",
    "\n",
    "Now that all 12 months are combined, I'll examine the complete dataset to identify any data quality issues, missing values, and understand the overall structure before cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4cb3294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "============================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5860568 entries, 0 to 5860567\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   ride_id             object \n",
      " 1   rideable_type       object \n",
      " 2   started_at          object \n",
      " 3   ended_at            object \n",
      " 4   start_station_name  object \n",
      " 5   start_station_id    object \n",
      " 6   end_station_name    object \n",
      " 7   end_station_id      object \n",
      " 8   start_lat           float64\n",
      " 9   start_lng           float64\n",
      " 10  end_lat             float64\n",
      " 11  end_lng             float64\n",
      " 12  member_casual       object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 581.3+ MB\n",
      "\n",
      "Column Data Types:\n",
      "------------------------------------------------------------\n",
      "ride_id                object\n",
      "rideable_type          object\n",
      "started_at             object\n",
      "ended_at               object\n",
      "start_station_name     object\n",
      "start_station_id       object\n",
      "end_station_name       object\n",
      "end_station_id         object\n",
      "start_lat             float64\n",
      "start_lng             float64\n",
      "end_lat               float64\n",
      "end_lng               float64\n",
      "member_casual          object\n",
      "dtype: object\n",
      "\n",
      "First 3 rows:\n",
      "            ride_id  rideable_type           started_at             ended_at  \\\n",
      "0  C1D650626C8C899A  electric_bike  2024-01-12 15:30:27  2024-01-12 15:37:59   \n",
      "1  EECD38BDB25BFCB0  electric_bike  2024-01-08 15:45:46  2024-01-08 15:52:59   \n",
      "2  F4A9CE78061F17F7  electric_bike  2024-01-27 12:27:19  2024-01-27 12:35:19   \n",
      "\n",
      "  start_station_name start_station_id          end_station_name  \\\n",
      "0  Wells St & Elm St     KA1504000135  Kingsbury St & Kinzie St   \n",
      "1  Wells St & Elm St     KA1504000135  Kingsbury St & Kinzie St   \n",
      "2  Wells St & Elm St     KA1504000135  Kingsbury St & Kinzie St   \n",
      "\n",
      "  end_station_id  start_lat  start_lng    end_lat    end_lng member_casual  \n",
      "0   KA1503000043  41.903267 -87.634737  41.889177 -87.638506        member  \n",
      "1   KA1503000043  41.902937 -87.634440  41.889177 -87.638506        member  \n",
      "2   KA1503000043  41.902951 -87.634470  41.889177 -87.638506        member  \n",
      "\n",
      "Last 3 rows:\n",
      "                  ride_id  rideable_type               started_at  \\\n",
      "5860565  15602635C5DF484E  electric_bike  2024-12-31 17:10:03.113   \n",
      "5860566  F15ABBA961560B75  electric_bike  2024-12-01 14:39:47.216   \n",
      "5860567  8AF273287533B527  electric_bike  2024-12-17 06:38:32.320   \n",
      "\n",
      "                        ended_at             start_station_name  \\\n",
      "5860565  2024-12-31 17:17:21.838  Albany Ave & Bloomingdale Ave   \n",
      "5860566  2024-12-01 14:45:21.268  Albany Ave & Bloomingdale Ave   \n",
      "5860567  2024-12-17 06:46:27.167  Albany Ave & Bloomingdale Ave   \n",
      "\n",
      "        start_station_id                end_station_name end_station_id  \\\n",
      "5860565            15655  California Ave & Milwaukee Ave          13084   \n",
      "5860566            15655  California Ave & Milwaukee Ave          13084   \n",
      "5860567            15655                             NaN            NaN   \n",
      "\n",
      "         start_lat  start_lng    end_lat    end_lng member_casual  \n",
      "5860565  41.914027 -87.705126  41.922695 -87.697153        member  \n",
      "5860566  41.914003 -87.705099  41.922695 -87.697153        member  \n",
      "5860567  41.914027 -87.705126  41.920000 -87.690000        member  \n",
      "Missing Values Analysis:\n",
      "------------------------------------------------------------\n",
      "            Column  Missing_Count  Missing_Percentage\n",
      "    end_station_id        1104653               18.85\n",
      "  end_station_name        1104653               18.85\n",
      "  start_station_id        1073951               18.33\n",
      "start_station_name        1073951               18.33\n",
      "           end_lat           7232                0.12\n",
      "           end_lng           7232                0.12\n"
     ]
    }
   ],
   "source": [
    "# Display overall information about the dataset\n",
    "print(\"Dataset Information:\")\n",
    "print('=' * 60)\n",
    "df.info()\n",
    "\n",
    "# Check what data type each column is\n",
    "print(\"\\nColumn Data Types:\")\n",
    "print(\"-\" * 60)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Look at the first 3 rows\n",
    "print(\"\\nFirst 3 rows:\")\n",
    "print(df.head(3))\n",
    "\n",
    "# Look at the last 3 rows\n",
    "print(\"\\nLast 3 rows:\")\n",
    "print(df.tail(3))\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Create a list to store missing value information\n",
    "missing_info = []\n",
    "\n",
    "# Loop through each column\n",
    "for column_name in df.columns:\n",
    "    # Count how many values are missing\n",
    "    missing_count = df[column_name].isnull().sum()\n",
    "    \n",
    "    # Calculate percentage of missing values\n",
    "    total_rows = len(df)\n",
    "    missing_percentage = (missing_count / total_rows) * 100\n",
    "    missing_percentage = round(missing_percentage, 2)\n",
    "    \n",
    "    # Add to our list\n",
    "    missing_info.append({\n",
    "        'Column': column_name,\n",
    "        'Missing_Count': missing_count,\n",
    "        'Missing_Percentage': missing_percentage\n",
    "    })\n",
    "\n",
    "# Convert to dataframe\n",
    "missing_data = pd.DataFrame(missing_info)\n",
    "\n",
    "# Keep only columns that have missing values\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0]\n",
    "\n",
    "# Sort by missing count (highest first)\n",
    "missing_data = missing_data.sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(missing_data.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4acd66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Member Type Distribution:\n",
      "------------------------------------------------------------\n",
      "                 Count  Percentage\n",
      "member_casual                     \n",
      "member         3708910    0.632858\n",
      "casual         2151658    0.367142\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of member types\n",
    "print(\"\\nMember Type Distribution:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Count how many members vs casual riders\n",
    "member_counts = df['member_casual'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each type\n",
    "member_percent = df['member_casual'].value_counts(normalize=True)\n",
    "\n",
    "# Combine into one table\n",
    "distribution = pd.DataFrame({\n",
    "    'Count' : member_counts,\n",
    "    'Percentage' : member_percent\n",
    "})\n",
    "\n",
    "print(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8b4722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rideable Type Distribution:\n",
      "------------------------------------------------------------\n",
      "rideable_type\n",
      "electric_bike       2980595\n",
      "classic_bike        2735636\n",
      "electric_scooter     144337\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of bike types\n",
    "print(\"\\nRideable Type Distribution:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Count how many of each bike type\n",
    "rideable_counts = df['rideable_type'].value_counts()\n",
    "print(rideable_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b57da",
   "metadata": {},
   "source": [
    "### Saving Combined Dataset\n",
    "\n",
    "I'm saving the combined raw dataset before any cleaning. This preserves the original data for reference and ensures I can reproduce my work if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "552cd0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined raw data saved to: ../data/raw/combined_2024_raw.csv\n"
     ]
    }
   ],
   "source": [
    "# Define where to save the combined file\n",
    "output_path = '../data/raw/combined_2024_raw.csv'\n",
    "\n",
    "# Save the dataframe to CSV without the index column\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Confirm the file was saved\n",
    "print(f'Combined raw data saved to: {output_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
